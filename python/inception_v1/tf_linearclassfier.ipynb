{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from bigdl.nn.layer import *\n",
    "from bigdl.nn.criterion import *\n",
    "from bigdl.optim.optimizer import *\n",
    "from bigdl.util.common import *\n",
    "from bigdl.dataset.transformer import *\n",
    "from bigdl.dataset import mnist\n",
    "\n",
    "init_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Poultry': 5, 'Pork': 4, 'Fresh, chilled or frozen fish and seafood': 3, 'Fresh or chilled potatoes': 2, 'Lamb, mutton and goat': 8, 'Egg and egg-based products': 7, 'Fresh or chilled fruit': 1, 'Fresh or chilled vegetables other than potatoes': 0, 'Beef and veal': 6}\n",
      "(2176,)\n",
      "(435,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Generate Sorted Labels from csv\n",
    "'''\n",
    "df = pd.read_csv(\"~/Downloads/vegnonveg-samples_labels.csv\")\n",
    "df = df.sort_values(by='obs_uid', axis = 0)\n",
    "\n",
    "'''\n",
    "Labels are stored here\n",
    "'''\n",
    "nums = range(0,9)\n",
    "categ = df.bh_name.unique()\n",
    "label_dict = dict(zip(categ, nums))\n",
    "\n",
    "print label_dict\n",
    "\n",
    "train_labels = df['bh_name'][0:2176].map(label_dict).get_values()\n",
    "test_labels = df['bh_name'][2176:].map(label_dict).get_values()\n",
    "print train_labels.shape\n",
    "print test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "#list of 1024 numpy arrays (bottlenecks)\n",
    "bottlenecks = pickle.load(open(\"pickle_bottleneck.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2176, 1024)\n",
      "(435, 1024)\n"
     ]
    }
   ],
   "source": [
    "bottlenecks_adj = np.array(bottlenecks)\n",
    "train_images = bottlenecks_adj[0:2176]\n",
    "test_images = bottlenecks_adj[2176:]\n",
    "\n",
    "print train_images.shape\n",
    "print test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_rdd(train_images, test_images, train_labels, test_labels):\n",
    "#     training_mean = np.mean(train_images)\n",
    "#     training_std = np.std(train_images)\n",
    "#     rdd_train_images = sc.parallelize(train_images)\n",
    "#     rdd_train_labels = sc.parallelize(train_labels)\n",
    "#     rdd_test_images = sc.parallelize(test_images)\n",
    "#     rdd_test_labels = sc.parallelize(test_labels)\n",
    "\n",
    "#     rdd_train_sample = rdd_train_images.zip(rdd_train_labels).map(lambda (features, label):Sample.from_ndarray(\n",
    "#                                         (features - training_mean) / training_std,\n",
    "#                                         label + 1))\n",
    "#     rdd_test_sample = rdd_test_images.zip(rdd_test_labels).map(lambda (features, label):Sample.from_ndarray(\n",
    "#                                         (features - training_mean) / training_std,\n",
    "#                                         label + 1))\n",
    "#     return (rdd_train_sample, rdd_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rdd(train_images, test_images, train_labels, test_labels):\n",
    "    rdd_train_images = sc.parallelize(train_images)\n",
    "    rdd_train_labels = sc.parallelize(train_labels)\n",
    "    rdd_test_images = sc.parallelize(test_images)\n",
    "    rdd_test_labels = sc.parallelize(test_labels)\n",
    "\n",
    "    rdd_train_sample = rdd_train_images.zip(rdd_train_labels).map(lambda (features, label): Sample.from_ndarray((features),label + 1))\n",
    "    rdd_test_sample = rdd_test_images.zip(rdd_test_labels).map(lambda (features, label):Sample.from_ndarray((features),label + 1))\n",
    "    return (rdd_train_sample, rdd_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_data, test_data) = get_rdd(train_images, test_images, train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2176\n",
      "435\n"
     ]
    }
   ],
   "source": [
    "print train_data.count()\n",
    "print test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.2\n",
    "training_epochs = 40\n",
    "batch_size = 60\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 1024 # 1024\n",
    "n_classes = 9 # bh_name categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createSequential\n",
      "creating: createLinear\n",
      "creating: createLogSoftMax\n"
     ]
    }
   ],
   "source": [
    "def fc_layer(n_input, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Linear(n_input, n_classes))\n",
    "    model.add(LogSoftMax())\n",
    "    return model# Create an Optimizer\n",
    "\n",
    "model = fc_layer(n_input, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createClassNLLCriterion\n",
      "creating: createDefault\n",
      "creating: createSGD\n",
      "creating: createMaxEpoch\n",
      "creating: createOptimizer\n",
      "creating: createEveryEpoch\n",
      "creating: createTop1Accuracy\n",
      "creating: createTrainSummary\n",
      "creating: createSeveralIteration\n",
      "creating: createValidationSummary\n",
      "saving logs to  linear-\n"
     ]
    }
   ],
   "source": [
    "optimizer = Optimizer(\n",
    "    model=model,\n",
    "    training_rdd=train_data,\n",
    "    criterion=ClassNLLCriterion(),\n",
    "    optim_method=SGD(learningrate=learning_rate),\n",
    "    end_trigger=MaxEpoch(training_epochs),\n",
    "    batch_size=batch_size)\n",
    "# Set the validation logic\n",
    "optimizer.set_validation(\n",
    "    batch_size=batch_size,\n",
    "    val_rdd=test_data,\n",
    "    trigger=EveryEpoch(),\n",
    "    val_method=[Top1Accuracy()]\n",
    ")\n",
    "\n",
    "app_name= 'linear-' # + dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_summary = TrainSummary(log_dir='/tmp/bigdl_summaries',\n",
    "                                     app_name=app_name)\n",
    "train_summary.set_summary_trigger(\"Parameters\", SeveralIteration(50))\n",
    "val_summary = ValidationSummary(log_dir='/tmp/bigdl_summaries',\n",
    "                                        app_name=app_name)\n",
    "optimizer.set_train_summary(train_summary)\n",
    "optimizer.set_val_summary(val_summary)\n",
    "print \"saving logs to \",app_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Done.\n"
     ]
    }
   ],
   "source": [
    "# Start to train\n",
    "trained_model = optimizer.optimize()\n",
    "print \"Optimization Done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_predict_label(l):\n",
    "    return np.array(l).argmax()\n",
    "def map_groundtruth_label(l):\n",
    "    return l[0] - 1\n",
    "def map_to_label(l):\n",
    "    return label_dict.keys()[label_dict.values().index(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth labels:\n",
      "Fresh or chilled potatoes\n",
      " Fresh or chilled potatoes\n",
      " Fresh or chilled fruit\n",
      " Fresh or chilled fruit\n",
      " Fresh, chilled or frozen fish and seafood\n",
      " Fresh or chilled fruit\n",
      " Fresh or chilled potatoes\n",
      " Egg and egg-based products\n",
      "\n",
      "\n",
      "Predicted labels:\n",
      "Fresh or chilled potatoes\n",
      " Fresh or chilled potatoes\n",
      " Fresh or chilled fruit\n",
      " Fresh or chilled vegetables other than potatoes\n",
      " Fresh, chilled or frozen fish and seafood\n",
      " Fresh or chilled fruit\n",
      " Fresh or chilled fruit\n",
      " Fresh or chilled potatoes\n"
     ]
    }
   ],
   "source": [
    "predictions = trained_model.predict(test_data)\n",
    "\n",
    "print 'Ground Truth labels:'\n",
    "print '\\n '.join(str(map_to_label(map_groundtruth_label(s.label))) for s in test_data.take(8))\n",
    "#print 'Ground Truth:'\n",
    "#print '\\t'.join([str(s.label) for s in ground_truth])\n",
    "print \"\\n\"\n",
    "print 'Predicted labels:'\n",
    "print '\\n '.join(str(map_to_label(map_predict_label(s))) for s in predictions.take(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createTop1Accuracy\n",
      "Test result: 0.698850572109, total_num: 435, method: Top1Accuracy\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Measure Test Accuracy\n",
    "'''\n",
    "results = trained_model.test(test_data, 200, [Top1Accuracy()])\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
